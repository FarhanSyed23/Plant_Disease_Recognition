{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Rag Thresholding"
      ],
      "metadata": {
        "id": "GPNnBUmCGQfX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxtyhClYFXpl"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import xgboost as xgb\n",
        "import imutils \n",
        "from imutils import paths\n",
        "from skimage import data, segmentation, color, filters\n",
        "from skimage.transform import resize\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "base_path = 'C:/Users/Farhan/Desktop/Pattern Project/Plant_sample100'\n",
        "categories = ['Cherry___healthy', 'Cherry_Powdery_mildew', 'Corn___healthy', \n",
        "              'Corn_Common_rust', 'Grape___healthy', 'Grape_Isariopsis_Leaf_Spot']\n",
        "f_names = []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading File Name "
      ],
      "metadata": {
        "id": "19-nJmfZHHvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for category in categories:\n",
        "    fold_plant = os.path.join(base_path, category)\n",
        "    file_names = os.listdir(fold_plant)\n",
        "    full_path = [os.path.join(fold_plant, file_name) for file_name in file_names]\n",
        "    f_names.append(full_path)"
      ],
      "metadata": {
        "id": "-8GL1iymG_z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading Images"
      ],
      "metadata": {
        "id": "v4RegxZ1Hce8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "for names in f_names:\n",
        "    one_category_images = [cv2.imread(name) for name in names if (cv2.imread(name)) is not None]\n",
        "    images.append(one_category_images)\n",
        "print('Number of images for each category:', [len(f) for f in images])"
      ],
      "metadata": {
        "id": "V-TnHGyZHbQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identifying Minimum Shape for Images"
      ],
      "metadata": {
        "id": "duysZsC9Hx31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i,imgs in enumerate(images):\n",
        "    shapes = [img.shape for img in imgs]\n",
        "    widths = [shape[0] for shape in shapes]\n",
        "    heights = [shape[1] for shape in shapes]\n",
        "    print('%d,%d is the min shape for %s' % (np.min(widths), np.min(heights), categories[i]))\n",
        "print('\\n')\n",
        "def bgr2rgb(img):\n",
        "    return cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "LrgT02gJHqIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resize Image"
      ],
      "metadata": {
        "id": "rNPiS8IuH_OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_feature_vector(images, size=(128, 128)):\n",
        "    return cv2.resize(images, size).flatten()"
      ],
      "metadata": {
        "id": "7Rk9izjwH9Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3D Histogram"
      ],
      "metadata": {
        "id": "Z40aT3spIY1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_color_histogram(imgs, bins=(16, 16, 16)):\n",
        "    hsv = cv2.cvtColor(imgs, cv2.COLOR_BGR2RGB)\n",
        "    h_gram = cv2.calcHist([hsv], [0, 1, 2], None, bins,[0, 180, 0, 256, 0, 256])\n",
        "    if imutils.is_cv2():\n",
        "        h_gram = cv2.normalize(h_gram)\n",
        "    else:\n",
        "        cv2.normalize(h_gram, h_gram)\n",
        "    return h_gram.flatten()"
      ],
      "metadata": {
        "id": "R88g24BlIWdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ##   Segmentation with Rag Thresholding"
      ],
      "metadata": {
        "id": "3ZjET_dXJIJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "rawImages = []\n",
        "features = []\n",
        "\n",
        "imagePaths = list(paths.list_images(base_path))\n",
        "\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "    \n",
        "    fig, axes = plt.subplots(ncols=3, figsize=(15, 3.5))\n",
        "    ax = axes.ravel()\n",
        "    ax[0] = plt.subplot(1, 3, 1)\n",
        "    ax[1] = plt.subplot(1, 3, 2)\n",
        "    ax[2] = plt.subplot(1, 3, 3) \n",
        "    \n",
        "    image = cv2.imread(imagePath)\n",
        "\n",
        "    ax[0].imshow(bgr2rgb(image))\n",
        "    ax[0].set_title('Original')\n",
        "    ax[0].axis('off')\n",
        "    \n",
        "    label = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
        "\n",
        "    #   segmentation with Rag_thresholding..................................................................\n",
        "    labels1 = segmentation.slic(image, compactness=30, n_segments=400)\n",
        "    out = color.label2rgb(labels1, image, kind='avg')\n",
        "\n",
        "    ax[1].imshow(out)\n",
        "    ax[1].set_title('Segmented picture')\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    h_gram = extract_color_histogram(out)\n",
        "    pixels = image_to_feature_vector(out)\n",
        "    rawImages.append(pixels)                   # features\n",
        "    labels.append(label)\n",
        "    features.append(h_gram)\n",
        "\n",
        "    ax[2].hist(out.ravel(),256,[0,256], color='r')\n",
        "    ax[2].set_title('Histogram')\n",
        "        \n",
        "    plt.show()\n",
        "\n",
        "rawImages = np.array(rawImages)               # show some information on the memory consumed by the raw images matrix and features matrix\n",
        "labels = np.array(labels)\n",
        "features = np.array(features)\n",
        "\n",
        "print(\"[INFO] pixels matrix:   {:.2f} MB\".format(rawImages.nbytes / (1024 * 1000.0)))\n",
        "print(\"[INFO] features matrix: {:.2f} MB\\n\".format(features.nbytes / (1024 * 1000.0)))"
      ],
      "metadata": {
        "id": "lHCkwWKGIkdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train-Test Split"
      ],
      "metadata": {
        "id": "UYnHXrmhJTYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(rawImages, labels, test_size=0.25, random_state=22)\n",
        "(train_Feat, test_Feat, train_Labels, test_Labels) = train_test_split(features, labels, test_size=0.25, random_state=22)"
      ],
      "metadata": {
        "id": "4A-S1lh2JZE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decision Tree Classifier:"
      ],
      "metadata": {
        "id": "SX6jWDoWJhp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dclf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "Dclf1 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "\n",
        "Dclf.fit(X_train,y_train)\n",
        "Dclf1.fit(train_Feat,train_Labels)\n",
        "\n",
        "Dy_pred = Dclf.predict(X_test)\n",
        "Dy_pred1=Dclf1.predict(test_Feat)\n",
        "print(\"\\nDecision Tree Classifier: \\n\")\n",
        "\n",
        "result2 = confusion_matrix(y_test, Dy_pred)\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, Dy_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "D_acc=metrics.accuracy_score(y_test, Dy_pred)\n",
        "print(\"Accuracy of decision tree: {:.2f} %\".format(D_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, Dy_pred1)*100))\n"
      ],
      "metadata": {
        "id": "uki2EngeJigc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest Classifier:"
      ],
      "metadata": {
        "id": "x6Kf7DmzJ02W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf=RandomForestClassifier(n_estimators=90)\n",
        "clf1=RandomForestClassifier(n_estimators=90)\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "clf1.fit(train_Feat,train_Labels)\n",
        "\n",
        "r_pred = clf.predict(X_test)\n",
        "r_pred1 = clf1.predict(test_Feat)\n",
        "\n",
        "print(\"\\nRandom Forest Classifier: \\n\")\n",
        "result = confusion_matrix(y_test, r_pred)\n",
        "print(\"Confusion Matrix: \\n\")\n",
        "print(result)\n",
        "\n",
        "result1 = classification_report(y_test, r_pred)\n",
        "print(\"Classification Report: \\n\")\n",
        "print(result1)\n",
        "R_acc=(metrics.accuracy_score(y_test, r_pred))\n",
        "\n",
        "print(\"Accuracy of Random Forest:{:.2f} %\".format(R_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, r_pred1)*100))\n"
      ],
      "metadata": {
        "id": "6PV_j3xpJz2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Naive Bayes Classifier:"
      ],
      "metadata": {
        "id": "7RwJGVL1KGVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "gnb1 = GaussianNB()\n",
        "\n",
        "gnb.fit(X_train,y_train)\n",
        "gnb1.fit(train_Feat,train_Labels)\n",
        "\n",
        "Ny_pred = gnb.predict(X_test)\n",
        "Ny_pred1=gnb1.predict(test_Feat)\n",
        "print(\"\\nNaive Bayes Classifier: \\n\")\n",
        "\n",
        "result2 = confusion_matrix(y_test, Ny_pred)\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, Ny_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "N_acc=metrics.accuracy_score(y_test, Ny_pred)\n",
        "print(\"Accuracy of Naive Bayes Classifier: {:.2f} %\".format(N_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, Ny_pred1)*100))"
      ],
      "metadata": {
        "id": "YLaLX4kOKDn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM Classifier:"
      ],
      "metadata": {
        "id": "DOfaLeeQKZ1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Sclf = svm.SVC(kernel='linear')\n",
        "Sclf1 = svm.SVC(kernel='linear')\n",
        "\n",
        "Sclf.fit(X_train,y_train)\n",
        "Sclf1.fit(train_Feat,train_Labels)\n",
        "\n",
        "Sy_pred = Sclf.predict(X_test)\n",
        "Sy_pred1=Sclf1.predict(test_Feat)\n",
        "print(\"\\nSVM Classifier: \\n\")\n",
        "result2 = confusion_matrix(y_test, Sy_pred)\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, Sy_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "S_acc=metrics.accuracy_score(y_test, Sy_pred)\n",
        "print(\"Accuracy of SVM Classifier: {:.2f} %\".format(S_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, Sy_pred1)*100))\n"
      ],
      "metadata": {
        "id": "__dMNkDTKY21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##xgBoost classifier:"
      ],
      "metadata": {
        "id": "AgetHyUsKpsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xg_cl = xgb.XGBClassifier(n_estimators=10,objective ='binary:logistic',colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10,)\n",
        "xg_cl1 = xgb.XGBClassifier(n_estimators=10,objective ='binary:logistic',colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10,)\n",
        "\n",
        "xg_cl.fit(X_train,y_train)\n",
        "xg_cl1.fit(train_Feat,train_Labels)\n",
        "\n",
        "xgy_pred = xg_cl.predict(X_test)\n",
        "xgy_pred1=xg_cl1.predict(test_Feat)\n",
        "print(\"\\nxgBoost Classifier: \\n\")\n",
        "result2 = confusion_matrix(y_test, xgy_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, xgy_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "xg_acc=metrics.accuracy_score(y_test, xgy_pred)\n",
        "print(\"Accuracy of xgBoost Classifier: {:.2f} %\".format(xg_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, xgy_pred1)*100))"
      ],
      "metadata": {
        "id": "AHoz8MKrKmn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KNN Classifier:"
      ],
      "metadata": {
        "id": "-EQst3XBK3Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neighbors = [1, 3, 5, 7, 9]\n",
        "k_pred = []\n",
        "\n",
        "for k in neighbors:\n",
        "    print(f\"\\nKNN classifier ( k = {k})\\n\")\n",
        "    knn = KNeighborsClassifier(n_neighbors= k)\n",
        "    knn.fit(X_train,y_train)\n",
        "    \n",
        "    y_predi = knn.predict(X_test)\n",
        "    prediction = metrics.accuracy_score(y_test, y_predi)\n",
        "    k_pred.append(prediction)\n",
        "        \n",
        "    CM= confusion_matrix(y_test,y_predi)\n",
        "    print(\"Confusion Matrix:\\n\")\n",
        "    print(CM)\n",
        "    classi=classification_report(y_test,y_predi)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classi)\n",
        "\n",
        "    knn.fit(train_Feat,train_Labels)\n",
        "    k_acc=knn.score(test_Feat,test_Labels)\n",
        "\n",
        "    print(\"Accuracy of KNN: {:.1f} %\".format(prediction * 100))\n",
        "    print(f\"Accuracy of features : {k_acc * 100} %\")"
      ],
      "metadata": {
        "id": "PZaEInLvKzKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Plotting Accuracy"
      ],
      "metadata": {
        "id": "Df4orcLJLF2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height = [D_acc*100, R_acc*100, N_acc*100, S_acc*100, xg_acc*100, \n",
        "          k_pred[0]*100, k_pred[1]*100, k_pred[2]*100, k_pred[3]*100, k_pred[4]*100]\n",
        "bars = ('Decision tree', 'Random', 'Naive Bayes','SVM', 'xGBoost', \n",
        "        'KNN_1', 'KNN_3', 'KNN_5', 'KNN_7', 'KNN_9')\n",
        "y_pos = np.arange(len(bars))\n",
        "\n",
        "plt.figure(figsize=(20, 12))\n",
        "plt.bar(y_pos, height, color=['red', 'palegreen', 'green', 'blue', 'yellow', 'brown', 'magenta', 'pink', 'magenta', 'pink'])\n",
        "plt.xticks(y_pos, bars)\n",
        "plt.title('Accuracy Comparision', size = 30)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dWc9aI6uLD-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Region Rag"
      ],
      "metadata": {
        "id": "VfzpRECUGmMR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EfBn9CCFXpz"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import xgboost as xgb\n",
        "import imutils \n",
        "from imutils import paths\n",
        "from skimage import data, segmentation, color, filters\n",
        "from skimage.transform import resize\n",
        "from skimage.future import graph\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "base_path = 'C:/Users/Farhan/Desktop/Pattern Project/Plant_sample100'\n",
        "categories = ['Cherry___healthy', 'Cherry_Powdery_mildew', 'Corn___healthy', \n",
        "              'Corn_Common_rust', 'Grape___healthy', 'Grape_Isariopsis_Leaf_Spot']\n",
        "f_names = []\n",
        "\n",
        "# reading file name \n",
        "for category in categories:\n",
        "    fold_plant = os.path.join(base_path, category)\n",
        "    file_names = os.listdir(fold_plant)\n",
        "    full_path = [os.path.join(fold_plant, file_name) for file_name in file_names]\n",
        "    f_names.append(full_path)\n",
        "\n",
        "# reading images\n",
        "images = []\n",
        "for names in f_names:\n",
        "    one_category_images = [cv2.imread(name) for name in names if (cv2.imread(name)) is not None]\n",
        "    images.append(one_category_images)\n",
        "print('Number of images for each category:', [len(f) for f in images])\n",
        "\n",
        "# identifying minimum shape for images\n",
        "for i,imgs in enumerate(images):\n",
        "    shapes = [img.shape for img in imgs]\n",
        "    widths = [shape[0] for shape in shapes]\n",
        "    heights = [shape[1] for shape in shapes]\n",
        "    print('%d,%d is the min shape for %s' % (np.min(widths), np.min(heights), categories[i]))\n",
        "print('\\n')\n",
        "def bgr2rgb(img):\n",
        "    return cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
        "# resize image\n",
        "def image_to_feature_vector(images, size=(128, 128)):\n",
        "    return cv2.resize(images, size).flatten()\n",
        "# 3D histogram\n",
        "def extract_color_histogram(imgs, bins=(16, 16, 16)):\n",
        "    hsv = cv2.cvtColor(imgs, cv2.COLOR_BGR2RGB)\n",
        "    h_gram = cv2.calcHist([hsv], [0, 1, 2], None, bins,[0, 180, 0, 256, 0, 256])\n",
        "    if imutils.is_cv2():\n",
        "        h_gram = cv2.normalize(h_gram)\n",
        "    else:\n",
        "        cv2.normalize(h_gram, h_gram)\n",
        "    return h_gram.flatten()\n",
        "\n",
        "def weight_boundary(graph, src, dst, n):\n",
        "    default = {'weight': 0.0, 'count': 0}\n",
        "\n",
        "    count_src = graph[src].get(n, default)['count']\n",
        "    count_dst = graph[dst].get(n, default)['count']\n",
        "\n",
        "    weight_src = graph[src].get(n, default)['weight']\n",
        "    weight_dst = graph[dst].get(n, default)['weight']\n",
        "\n",
        "    count = count_src + count_dst\n",
        "    return {\n",
        "        'count': count,\n",
        "        'weight': (count_src * weight_src + count_dst * weight_dst)/count\n",
        "    }\n",
        "\n",
        "def merge_boundary(graph, src, dst):\n",
        "    pass\n",
        "\n",
        "labels = []\n",
        "rawImages = []\n",
        "features = []\n",
        "\n",
        "imagePaths = list(paths.list_images(base_path))\n",
        "\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "    \n",
        "    fig, axes = plt.subplots(ncols=3, figsize=(15, 3.5))\n",
        "    ax = axes.ravel()\n",
        "    ax[0] = plt.subplot(1, 3, 1)\n",
        "    ax[1] = plt.subplot(1, 3, 2)\n",
        "    ax[2] = plt.subplot(1, 3, 3) \n",
        "    \n",
        "    image = cv2.imread(imagePath)\n",
        "\n",
        "    ax[0].imshow(bgr2rgb(image))\n",
        "    ax[0].set_title('Original')\n",
        "    ax[0].axis('off')\n",
        "    \n",
        "    label = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
        "    \n",
        "    edges = filters.sobel(color.rgb2gray(image))\n",
        "    labelss = segmentation.slic(image, compactness=30, n_segments=400)\n",
        "    g = graph.rag_boundary(labelss, edges)\n",
        "\n",
        "    graph.show_rag(labelss, g, image)\n",
        "    plt.title('Initial RAG')\n",
        "\n",
        "    labels2 = graph.merge_hierarchical(labelss, g, thresh=0.08, rag_copy=False,in_place_merge=True, merge_func=merge_boundary,weight_func=weight_boundary)\n",
        "\n",
        "    graph.show_rag(labelss, g, image)\n",
        "    plt.title('RAG after hierarchical merging')\n",
        "    \n",
        "    out = color.label2rgb(labels2, image, kind='avg')\n",
        "    ax[1].imshow(out)\n",
        "    ax[1].set_title('Segmented pic')\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    h_gram = extract_color_histogram(out)\n",
        "    pixels = image_to_feature_vector(out)\n",
        "    rawImages.append(pixels)                   # features\n",
        "    labels.append(label)\n",
        "    features.append(h_gram)\n",
        "\n",
        "    ax[2].hist(out.ravel(),256,[0,256], color='r')\n",
        "    ax[2].set_title('Histogram')\n",
        "        \n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "rawImages = np.array(rawImages)               # show some information on the memory consumed by the raw images matrix and features matrix\n",
        "labels = np.array(labels)\n",
        "features = np.array(features)\n",
        "\n",
        "print(\"[INFO] pixels matrix:   {:.2f} MB\".format(rawImages.nbytes / (1024 * 1000.0)))\n",
        "print(\"[INFO] features matrix: {:.2f} MB\\n\".format(features.nbytes / (1024 * 1000.0)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(rawImages, labels, test_size=0.25, random_state=22)\n",
        "(train_Feat, test_Feat, train_Labels, test_Labels) = train_test_split(features, labels, test_size=0.25, random_state=22)\n",
        "\n",
        "\n",
        "#Decision Tree Classifier:............................................................................\n",
        "\n",
        "Dclf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "Dclf1 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "\n",
        "Dclf.fit(X_train,y_train)\n",
        "Dclf1.fit(train_Feat,train_Labels)\n",
        "\n",
        "Dy_pred = Dclf.predict(X_test)\n",
        "Dy_pred1=Dclf1.predict(test_Feat)\n",
        "print(\"\\nDecision Tree Classifier: \\n\")\n",
        "\n",
        "result2 = confusion_matrix(y_test, Dy_pred)\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, Dy_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "D_acc=metrics.accuracy_score(y_test, Dy_pred)\n",
        "print(\"Accuracy of decision tree: {:.2f} %\".format(D_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, Dy_pred1)*100))\n",
        "\n",
        "#Random Forest Classifier:..................................................................................\n",
        "\n",
        "clf=RandomForestClassifier(n_estimators=90)\n",
        "clf1=RandomForestClassifier(n_estimators=90)\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "clf1.fit(train_Feat,train_Labels)\n",
        "\n",
        "r_pred = clf.predict(X_test)\n",
        "r_pred1 = clf1.predict(test_Feat)\n",
        "\n",
        "print(\"\\nRandom Forest Classifier: \\n\")\n",
        "result = confusion_matrix(y_test, r_pred)\n",
        "print(\"Confusion Matrix: \\n\")\n",
        "print(result)\n",
        "\n",
        "result1 = classification_report(y_test, r_pred)\n",
        "print(\"Classification Report: \\n\")\n",
        "print(result1)\n",
        "R_acc=(metrics.accuracy_score(y_test, r_pred))\n",
        "\n",
        "print(\"Accuracy of Random Forest:{:.2f} %\".format(R_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, r_pred1)*100))\n",
        "\n",
        "\n",
        "\n",
        "#Naive Bayes Classifier:........................................................................\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb1 = GaussianNB()\n",
        "\n",
        "gnb.fit(X_train,y_train)\n",
        "gnb1.fit(train_Feat,train_Labels)\n",
        "\n",
        "Ny_pred = gnb.predict(X_test)\n",
        "Ny_pred1=gnb1.predict(test_Feat)\n",
        "print(\"\\nNaive Bayes Classifier: \\n\")\n",
        "\n",
        "result2 = confusion_matrix(y_test, Ny_pred)\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, Ny_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "N_acc=metrics.accuracy_score(y_test, Ny_pred)\n",
        "print(\"Accuracy of Naive Bayes Classifier: {:.2f} %\".format(N_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, Ny_pred1)*100))\n",
        "\n",
        "#SVM Classifier:.....................................................................................\n",
        "\n",
        "Sclf = svm.SVC(kernel='linear')\n",
        "Sclf1 = svm.SVC(kernel='linear')\n",
        "\n",
        "Sclf.fit(X_train,y_train)\n",
        "Sclf1.fit(train_Feat,train_Labels)\n",
        "\n",
        "Sy_pred = Sclf.predict(X_test)\n",
        "Sy_pred1=Sclf1.predict(test_Feat)\n",
        "print(\"\\nSVM Classifier: \\n\")\n",
        "result2 = confusion_matrix(y_test, Sy_pred)\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, Sy_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "S_acc=metrics.accuracy_score(y_test, Sy_pred)\n",
        "print(\"Accuracy of SVM Classifier: {:.2f} %\".format(S_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, Sy_pred1)*100))\n",
        "\n",
        "\n",
        "#xgBoost classifier:.........................................................................\n",
        "\n",
        "\n",
        "xg_cl = xgb.XGBClassifier(n_estimators=10,objective ='binary:logistic',colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10,)\n",
        "xg_cl1 = xgb.XGBClassifier(n_estimators=10,objective ='binary:logistic',colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10,)\n",
        "\n",
        "xg_cl.fit(X_train,y_train)\n",
        "xg_cl1.fit(train_Feat,train_Labels)\n",
        "\n",
        "xgy_pred = xg_cl.predict(X_test)\n",
        "xgy_pred1=xg_cl1.predict(test_Feat)\n",
        "print(\"\\nxgBoost Classifier: \\n\")\n",
        "result2 = confusion_matrix(y_test, xgy_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, xgy_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "xg_acc=metrics.accuracy_score(y_test, xgy_pred)\n",
        "print(\"Accuracy of xgBoost Classifier: {:.2f} %\".format(xg_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, xgy_pred1)*100))\n",
        "\n",
        "#Knn Classifier:..................................................................................\n",
        "\n",
        "neighbors = [1, 3, 5, 7, 9]\n",
        "k_pred = []\n",
        "\n",
        "for k in neighbors:\n",
        "    print(f\"\\nKNN classifier ( k = {k})\\n\")\n",
        "    knn = KNeighborsClassifier(n_neighbors= k)\n",
        "    knn.fit(X_train,y_train)\n",
        "    \n",
        "    y_predi = knn.predict(X_test)\n",
        "    prediction = metrics.accuracy_score(y_test, y_predi)\n",
        "    k_pred.append(prediction)\n",
        "        \n",
        "    CM= confusion_matrix(y_test,y_predi)\n",
        "    print(\"Confusion Matrix:\\n\")\n",
        "    print(CM)\n",
        "    classi=classification_report(y_test,y_predi)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classi)\n",
        "\n",
        "    knn.fit(train_Feat,train_Labels)\n",
        "    k_acc=knn.score(test_Feat,test_Labels)\n",
        "\n",
        "    print(\"Accuracy of KNN: {:.1f} %\".format(prediction * 100))\n",
        "    print(f\"Accuracy of features : {k_acc * 100} %\")\n",
        "        \n",
        "#  Plotting Accuracy\n",
        "height = [D_acc*100, R_acc*100, N_acc*100, S_acc*100, xg_acc*100, \n",
        "          k_pred[0]*100, k_pred[1]*100, k_pred[2]*100, k_pred[3]*100, k_pred[4]*100]\n",
        "bars = ('Decision tree', 'Random', 'Naive Bayes','SVM', 'xGBoost', \n",
        "        'KNN_1', 'KNN_3', 'KNN_5', 'KNN_7', 'KNN_9')\n",
        "y_pos = np.arange(len(bars))\n",
        "\n",
        "plt.figure(figsize=(20, 12))\n",
        "plt.bar(y_pos, height, color=['red', 'palegreen', 'green', 'blue', 'yellow', 'brown', 'magenta', 'pink', 'magenta', 'pink'])\n",
        "plt.xticks(y_pos, bars)\n",
        "plt.title('Accuracy Comparision', size = 30)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grab Cut"
      ],
      "metadata": {
        "id": "TvMameWCGx9m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQFeDCtsFXp1"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import xgboost as xgb\n",
        "import imutils \n",
        "from imutils import paths\n",
        "from skimage import data, segmentation, color, filters\n",
        "from skimage.transform import resize\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "base_path = 'C:/Users/Farhan/Desktop/Pattern Project/Plant_sample100'\n",
        "categories = ['Cherry___healthy', 'Cherry_Powdery_mildew', 'Corn___healthy', \n",
        "              'Corn_Common_rust', 'Grape___healthy', 'Grape_Isariopsis_Leaf_Spot']\n",
        "f_names = []\n",
        "\n",
        "# reading file name \n",
        "for category in categories:\n",
        "    fold_plant = os.path.join(base_path, category)\n",
        "    file_names = os.listdir(fold_plant)\n",
        "    full_path = [os.path.join(fold_plant, file_name) for file_name in file_names]\n",
        "    f_names.append(full_path)\n",
        "\n",
        "# reading images\n",
        "images = []\n",
        "for names in f_names:\n",
        "    one_category_images = [cv2.imread(name) for name in names if (cv2.imread(name)) is not None]\n",
        "    images.append(one_category_images)\n",
        "print('Number of images for each category:', [len(f) for f in images])\n",
        "\n",
        "# identifying minimum shape for images\n",
        "for i,imgs in enumerate(images):\n",
        "    shapes = [img.shape for img in imgs]\n",
        "    widths = [shape[0] for shape in shapes]\n",
        "    heights = [shape[1] for shape in shapes]\n",
        "    print('%d,%d is the min shape for %s' % (np.min(widths), np.min(heights), categories[i]))\n",
        "print('\\n')\n",
        "def bgr2rgb(img):\n",
        "    return cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
        "# resize image\n",
        "def image_to_feature_vector(images, size=(128, 128)):\n",
        "    return cv2.resize(images, size).flatten()\n",
        "# 3D histogram\n",
        "def extract_color_histogram(imgs, bins=(16, 16, 16)):\n",
        "    hsv = cv2.cvtColor(imgs, cv2.COLOR_BGR2RGB)\n",
        "    h_gram = cv2.calcHist([hsv], [0, 1, 2], None, bins,[0, 180, 0, 256, 0, 256])\n",
        "    if imutils.is_cv2():\n",
        "        h_gram = cv2.normalize(h_gram)\n",
        "    else:\n",
        "        cv2.normalize(h_gram, h_gram)\n",
        "    return h_gram.flatten()\n",
        "\n",
        "labels = []\n",
        "rawImages = []\n",
        "features = []\n",
        "\n",
        "imagePaths = list(paths.list_images(base_path))\n",
        "\n",
        "\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "    \n",
        "    fig, axes = plt.subplots(ncols=3, figsize=(15, 3.5))\n",
        "    ax = axes.ravel()\n",
        "    ax[0] = plt.subplot(1, 3, 1)\n",
        "    ax[1] = plt.subplot(1, 3, 2)\n",
        "    ax[2] = plt.subplot(1, 3, 3) \n",
        "    \n",
        "    image = cv2.imread(imagePath)\n",
        "\n",
        "    ax[0].imshow(bgr2rgb(image))\n",
        "    ax[0].set_title('Original')\n",
        "    ax[0].axis('off')\n",
        "    \n",
        "    label = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
        "\n",
        "#   segmentation with Grab_cut..................................................................\n",
        "\n",
        "    mask = np.zeros(image.shape[:2],np.uint8)\n",
        "    bgdModel = np.zeros((1,65),np.float64)\n",
        "    fgdModel = np.zeros((1,65),np.float64)\n",
        "\n",
        "    rect = (3,3,950,950)\n",
        "    cv2.grabCut(image,mask,rect,bgdModel,fgdModel,3,cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "    mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "    g_cut = image*mask2[:,:,np.newaxis]\n",
        "\n",
        "    ax[1].imshow(g_cut)\n",
        "    ax[1].set_title('Segmented pic')\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    h_gram = extract_color_histogram(g_cut)\n",
        "    pixels = image_to_feature_vector(g_cut)\n",
        "    rawImages.append(pixels)                   # features\n",
        "    labels.append(label)\n",
        "    features.append(h_gram)\n",
        "\n",
        "    ax[2].hist(g_cut.ravel(),256,[0,256], color='r')\n",
        "    ax[2].set_title('Histogram')\n",
        "        \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "rawImages = np.array(rawImages)               # show some information on the memory consumed by the raw images matrix and features matrix\n",
        "labels = np.array(labels)\n",
        "features = np.array(features)\n",
        "\n",
        "print(\"[INFO] pixels matrix:   {:.2f} MB\".format(rawImages.nbytes / (1024 * 1000.0)))\n",
        "print(\"[INFO] features matrix: {:.2f} MB\\n\".format(features.nbytes / (1024 * 1000.0)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(rawImages, labels, test_size=0.25, random_state=22)\n",
        "(train_Feat, test_Feat, train_Labels, test_Labels) = train_test_split(features, labels, test_size=0.25, random_state=22)\n",
        "\n",
        "\n",
        "#Decision Tree Classifier:............................................................................\n",
        "\n",
        "Dclf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "Dclf1 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "\n",
        "Dclf.fit(X_train,y_train)\n",
        "Dclf1.fit(train_Feat,train_Labels)\n",
        "\n",
        "Dy_pred = Dclf.predict(X_test)\n",
        "Dy_pred1=Dclf1.predict(test_Feat)\n",
        "print(\"\\nDecision Tree Classifier: \\n\")\n",
        "\n",
        "result2 = confusion_matrix(y_test, Dy_pred)\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, Dy_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "D_acc=metrics.accuracy_score(y_test, Dy_pred)\n",
        "print(\"Accuracy of decision tree: {:.2f} %\".format(D_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, Dy_pred1)*100))\n",
        "\n",
        "#Random Forest Classifier:..................................................................................\n",
        "\n",
        "clf=RandomForestClassifier(n_estimators=90)\n",
        "clf1=RandomForestClassifier(n_estimators=90)\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "clf1.fit(train_Feat,train_Labels)\n",
        "\n",
        "r_pred = clf.predict(X_test)\n",
        "r_pred1 = clf1.predict(test_Feat)\n",
        "\n",
        "print(\"\\nRandom Forest Classifier: \\n\")\n",
        "result = confusion_matrix(y_test, r_pred)\n",
        "print(\"Confusion Matrix: \\n\")\n",
        "print(result)\n",
        "\n",
        "result1 = classification_report(y_test, r_pred)\n",
        "print(\"Classification Report: \\n\")\n",
        "print(result1)\n",
        "R_acc=(metrics.accuracy_score(y_test, r_pred))\n",
        "\n",
        "print(\"Accuracy of Random Forest:{:.2f} %\".format(R_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, r_pred1)*100))\n",
        "\n",
        "\n",
        "\n",
        "#Naive Bayes Classifier:........................................................................\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb1 = GaussianNB()\n",
        "\n",
        "gnb.fit(X_train,y_train)\n",
        "gnb1.fit(train_Feat,train_Labels)\n",
        "\n",
        "Ny_pred = gnb.predict(X_test)\n",
        "Ny_pred1=gnb1.predict(test_Feat)\n",
        "print(\"\\nNaive Bayes Classifier: \\n\")\n",
        "\n",
        "result2 = confusion_matrix(y_test, Ny_pred)\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, Ny_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "N_acc=metrics.accuracy_score(y_test, Ny_pred)\n",
        "print(\"Accuracy of Naive Bayes Classifier: {:.2f} %\".format(N_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, Ny_pred1)*100))\n",
        "\n",
        "#SVM Classifier:.....................................................................................\n",
        "\n",
        "Sclf = svm.SVC(kernel='linear')\n",
        "Sclf1 = svm.SVC(kernel='linear')\n",
        "\n",
        "Sclf.fit(X_train,y_train)\n",
        "Sclf1.fit(train_Feat,train_Labels)\n",
        "\n",
        "Sy_pred = Sclf.predict(X_test)\n",
        "Sy_pred1=Sclf1.predict(test_Feat)\n",
        "print(\"\\nSVM Classifier: \\n\")\n",
        "result2 = confusion_matrix(y_test, Sy_pred)\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, Sy_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "S_acc=metrics.accuracy_score(y_test, Sy_pred)\n",
        "print(\"Accuracy of SVM Classifier: {:.2f} %\".format(S_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, Sy_pred1)*100))\n",
        "\n",
        "\n",
        "#xgBoost classifier:.........................................................................\n",
        "\n",
        "\n",
        "xg_cl = xgb.XGBClassifier(n_estimators=10,objective ='binary:logistic',colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10,)\n",
        "xg_cl1 = xgb.XGBClassifier(n_estimators=10,objective ='binary:logistic',colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10,)\n",
        "\n",
        "xg_cl.fit(X_train,y_train)\n",
        "xg_cl1.fit(train_Feat,train_Labels)\n",
        "\n",
        "xgy_pred = xg_cl.predict(X_test)\n",
        "xgy_pred1=xg_cl1.predict(test_Feat)\n",
        "print(\"\\nxgBoost Classifier: \\n\")\n",
        "result2 = confusion_matrix(y_test, xgy_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(result2)\n",
        "\n",
        "result3 = classification_report(y_test, xgy_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result3)\n",
        "\n",
        "xg_acc=metrics.accuracy_score(y_test, xgy_pred)\n",
        "print(\"Accuracy of xgBoost Classifier: {:.2f} %\".format(xg_acc * 100))\n",
        "print(\"Accuracy of features : {:.2f} %\".format(metrics.accuracy_score(test_Labels, xgy_pred1)*100))\n",
        "\n",
        "#Knn Classifier:..................................................................................\n",
        "\n",
        "neighbors = [1, 3, 5, 7, 9]\n",
        "k_pred = []\n",
        "\n",
        "for k in neighbors:\n",
        "    print(f\"\\nKNN classifier ( k = {k})\\n\")\n",
        "    knn = KNeighborsClassifier(n_neighbors= k)\n",
        "    knn.fit(X_train,y_train)\n",
        "    \n",
        "    y_predi = knn.predict(X_test)\n",
        "    prediction = metrics.accuracy_score(y_test, y_predi)\n",
        "    k_pred.append(prediction)\n",
        "        \n",
        "    CM= confusion_matrix(y_test,y_predi)\n",
        "    print(\"Confusion Matrix:\\n\")\n",
        "    print(CM)\n",
        "    classi=classification_report(y_test,y_predi)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classi)\n",
        "\n",
        "    knn.fit(train_Feat,train_Labels)\n",
        "    k_acc=knn.score(test_Feat,test_Labels)\n",
        "\n",
        "    print(\"Accuracy of KNN: {:.1f} %\".format(prediction * 100))\n",
        "    print(f\"Accuracy of features : {k_acc * 100} %\")\n",
        "        \n",
        "#  Plotting Accuracy\n",
        "height = [D_acc*100, R_acc*100, N_acc*100, S_acc*100, xg_acc*100, \n",
        "          k_pred[0]*100, k_pred[1]*100, k_pred[2]*100, k_pred[3]*100, k_pred[4]*100]\n",
        "bars = ('Decision tree', 'Random', 'Naive Bayes','SVM', 'xGBoost', \n",
        "        'KNN_1', 'KNN_3', 'KNN_5', 'KNN_7', 'KNN_9')\n",
        "y_pos = np.arange(len(bars))\n",
        "\n",
        "plt.figure(figsize=(20, 12))\n",
        "plt.bar(y_pos, height, color=['red', 'palegreen', 'green', 'blue', 'yellow', 'brown', 'magenta', 'pink', 'magenta', 'pink'])\n",
        "plt.xticks(y_pos, bars)\n",
        "plt.title('Accuracy Comparision', size = 30)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}